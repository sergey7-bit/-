{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergey7-bit/-/blob/main/%D0%94%D0%97_Pro_23_%D0%B7%D0%B0%D0%BD%D1%8F%D1%82%D0%B8%D0%B5_%7C_GPT_Professional_%7C_%D0%9D%D0%B5%D0%B9%D1%80%D0%BE_%D0%BF%D1%80%D0%BE%D0%B4%D0%B0%D0%B6%D0%BD%D0%B8%D0%BA_%7C_%D0%A3%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap2ZHKyTo1Ox"
      },
      "source": [
        "#ДЗ Pro. GPT Professional. Нейро-продажник (урок 2).\n",
        "\n",
        "# Добавьте везде, где требуется код для подсчета стоимости диалога и рассчитайте стоимость диалога с учетом используемой модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8OwmMPirvmp"
      },
      "source": [
        "# Ваше решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAxpYmklPhpC"
      },
      "source": [
        "# Готовим окружение\n",
        "Устанавливаем пакеты.\n",
        "Подключаем библиотеки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6_okuN9-LDD8"
      },
      "outputs": [],
      "source": [
        "!pip  install openai langchain langchain-community faiss-cpu langchain-openai tiktoken >/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w4Gk-9iIzeqF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Определим класс для подсветки вывода разных моделей разными цветами\n",
        "# https://en.wikipedia.org/wiki/ANSI_escape_code#Colors\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKCYAN = '\\033[96m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    GREEN = '\\033[32m'\n",
        "    RED = '\\033[31m'\n",
        "    BGGREEN = \"\\033[102m\"\n",
        "    BGYELLOW = \"\\033[103m\"\n",
        "    BGCYAN = \"\\033[106m\"\n",
        "    BGMAGENTA = \"\\033[105m\"\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "9MpHZVZxWgkD"
      },
      "outputs": [],
      "source": [
        "#@title Грузим библиотеки\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "#import getpass\n",
        "\n",
        "import openai\n",
        "import tiktoken\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "import json\n",
        "import copy\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J1oPDxxf0FHC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Задаем константы\n",
        "gpt_4_turbo = 'gpt-4-1106-preview'\n",
        "gpt_35_turbo = 'gpt-3.5-turbo-1106'\n",
        "MODEL = gpt_35_turbo\n",
        "\n",
        "num_chunks = 5\n",
        "chunk_size = 940\n",
        "chunk_overlap = 0\n",
        "temp = 0.1\n",
        "verbose = 0\n",
        "knowledge_db_url = 'https://docs.google.com/document/d/17KU38YHm5qUwPSjJPiB3NtRtdFpvO-cK77PWwKEXj5E'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_DlA-Iudif0I",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Объявляем переменные\n",
        "history_chat = []\n",
        "history_user = []\n",
        "history_manager = []\n",
        "\n",
        "needs_extractor = []\n",
        "benefits_extractor = []\n",
        "objection_detector = []\n",
        "resolved_objection_detector = []\n",
        "tariff_detector = []\n",
        "\n",
        "main_answer = ''\n",
        "summarized_dialog = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "org-wcNI4jL7"
      },
      "source": [
        "# Модели GPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO2xc8JBAsK-"
      },
      "source": [
        "## get_topicphrase_questions -  ключи из последних сообщений\n",
        "\n",
        "эта генерация запускается после каждого нового вопроса пользователя, для выделения ключей в его сообщении, также выделяем ключи из последнего ответа\n",
        "менеджера, далее через корректора ключей создадим общий логический контекст общения (к накопленному списку ключей добавим новые и скорректируем логику)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "sU72p7GqAl2Z"
      },
      "outputs": [],
      "source": [
        "#@title Параметры\n",
        "name_todo_base = 'Экстрактор ключевых слов'\n",
        "model_todo_base = MODEL\n",
        "temperature_todo_base = 0\n",
        "verbose_base = 0\n",
        "\n",
        "system_topicphrase_extractor = '''\n",
        "Ты - эксперт по образовательным услугам Университета искусственного интеллекта (УИИ).\n",
        "topic phrase - это ключевое слово, ключевое словосочетание или ключевая фраза в тексте, отражающее смысл текста в контексте покупки-продажи\n",
        "курсов обучения искусственному интеллекту и программированию.\n",
        "Ты знаешь, что термины такие как: названия языков программирования, наименования курсов и названия тарифов - это всегда topic phrase.\n",
        "Ты никогда не включаешь в topic phrase имена людей.\n",
        "Твоя задача выделить в Тексте ключевые topic phrase и добавить их в список.\n",
        "Этот список будет использоваться для более эффективного поиска данных в базе знаний УИИ. Оцениваться будут четкость и сжатость списка.\n",
        "'''\n",
        "\n",
        "instructions_topicphrase_extractor = '''\n",
        "Проанализируй Текст и в своем ответе напиши кратко список самых лучших topic phrase в виде строки с разделителями (запятая).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "zPqEcsae5j5U"
      },
      "outputs": [],
      "source": [
        "#@title Функция\n",
        "def get_topicphrase_questions(name, _user, _manager, system, instruction, temp=0.0, verbose=verbose_base, model=MODEL):\n",
        "    #  в том, что история клиента не пустая мы уверены, проверим, что есть история менеджера\n",
        "    join_user = '\\n'.join(_user)\n",
        "    if history_manager:\n",
        "      text = f'Текст: {join_user}\\n\\n{_manager[-1]}'\n",
        "    else:\n",
        "      text = f'Текст: {join_user}'\n",
        "    messages = [  {\"role\": \"system\", \"content\": system},\n",
        "                  {\"role\": \"user\", \"content\": f'''{instruction}\n",
        "                                    \\n\\nТекст: {text}\n",
        "                                    \\n\\nОтвет: '''}\n",
        "                ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp,  # Используем более низкую температуру для более определенной суммаризации\n",
        "    )\n",
        "    answer = completion.choices[0].message.content\n",
        "    if verbose:\n",
        "      print(f'{bcolors.GREEN}{bcolors.BOLD}Ответ {name}:{bcolors.ENDC}\\n',\n",
        "            f'{bcolors.BGYELLOW}Ключевые слова для Базы знаний:{bcolors.ENDC}\\n {answer}\\n=========\\n')\n",
        "    return completion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLsRxipoEL4c"
      },
      "source": [
        "## get_hello - выделение приветствия в первом сообщении клиента\n",
        "\n",
        "Далее принудительно из ответов менеджера по продажам будем удалять приветствие, а в первом ответе менеджера отзеркалим приветствие клиента. Если клиент не поздоровался (или модель не опознала приветствие), добавим формально-нейтральное Здравствуйте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "3h9Wc-sm4zel"
      },
      "outputs": [],
      "source": [
        "#@title Параменты и функция\n",
        "def get_hello(model_gen, topic, temp=temp, verbose=verbose):\n",
        "  system = '''\n",
        "  Приветствие - это выражение приветствия или приветственное сообщение,\n",
        "  которое отправляется или произносится в начале общения с кем-либо.\n",
        "  Приветствие может быть формальным или неформальным, зависеть от культуры и контекста.\n",
        "  Оно служит для демонстрации вежливости, дружелюбия и желания установить контакт с собеседником.\n",
        "  Приветствия могут быть разными в различных языках и культурах, от простого 'привет' или 'здравствуйте'\n",
        "  до более формальных или традиционных выражений.\n",
        "  Твоя задача выявить в Тексте клиента Приветствие.\n",
        "  В свой ответ включи только найденное Приветствие.\n",
        "  Если в тексте клиента нет Приветствия, тогда напиши: 'None'.\n",
        "  '''\n",
        "  user = f'Текст клиента: {topic}'\n",
        "  messages = [{\"role\": \"system\", \"content\": system},{\"role\": \"user\", \"content\": user}]\n",
        "  completion = openai.chat.completions.create(model=model_gen, messages=messages, temperature=temp)\n",
        "\n",
        "  return completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-pEOGjVFC1U"
      },
      "source": [
        "## summarize_dialog - суммаризация диалога\n",
        "\n",
        "запускается перед работой диспетчера-маршрутизатора для формирования Хронологии предыдущих сообщений диалога. Всех специалистов будем просить строить свои ответы логичными относительно этой хронологии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sZO6AOKj-ZoW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Параметры и функция\n",
        "def summarize_dialog(dialog, _history, temp=0.1, verbose=0, model=MODEL):\n",
        "    i = 2 if len(_history) > 1 else 1  # берем 2 последних сообщения для саммаризации (предыд ответ менеджера и новый вопрос клиента)\n",
        "    last_statements = ' '.join(_history[-i:])\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": '''\n",
        "                  Ты супер корректор, умеешь выделять в диалогах все самое важное.\n",
        "                  Ты знаешь, что при саммаризации нельзя исключать из диалога специальные термины и названия курсов,\n",
        "                  программ и тарифов.\n",
        "                  Твоя задача сделать полное саммари на основании Истории предыдущих сообщений диалога и Последних сообщений.\n",
        "                                         '''},\n",
        "        {\"role\": \"user\", \"content\": f'''Суммаризируй Диалог, ничего не придумывай от себя. Если клиент представился, сохрани информацию об имени.\n",
        "                                      \\n\\nИстория предыдущих сообщений диалога: {dialog}.\n",
        "                                      \\n\\nПоследние сообщения: {last_statements}\n",
        "                                      \\n\\nОтвет: '''\n",
        "        }\n",
        "    ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp,  # Используем более низкую температуру для более определенной суммаризации\n",
        "    )\n",
        "    answer = completion.choices[0].message.content\n",
        "    if verbose:\n",
        "      print(f'{bcolors.BGYELLOW}Саммари диалога:{bcolors.ENDC}\\n', answer)\n",
        "    return completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtoExk0PGXe7"
      },
      "source": [
        "## extract_entity_from_user_question - выделяет сущности из последнего сообщения клиента/менеджера\n",
        "\n",
        "Искомые сущности: Возражения, Потребности, Преимущества, Отработка возражений, Тарифы и Цены"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyVzAGhEGwqU"
      },
      "source": [
        "### Параметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C4tAwJwiHA_6"
      },
      "outputs": [],
      "source": [
        "#@title 1. Выделение в последнем сообщении клиента озвученных им потребностей\n",
        "name_needs_extractor = 'Спец по потребностям'\n",
        "model_needs_extractor = MODEL\n",
        "temperature_needs_extractor = 0.2\n",
        "verbose_needs_extractor = 0\n",
        "system_prompt_needs_extractor = '''\n",
        "Ты лучший специалист отдела продаж. Ты продаешь курсы обучения искусственному интеллекту и программированию.\n",
        "Ты знаешь, что Потребность - это то, что клиент хочет или что ему нравится,\n",
        "и что повлияет на приобретение им курсов обучения.\n",
        "Ты очень хорошо умеешь выявлять в вопросе клиента его потребности.\n",
        "Ты всегда очень строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_needs_extractor = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Вопрос клиента, выяви высказанные в нем явные потребности клиента (если они есть) и напиши их.\n",
        "Ничего не придумывай от себя, если потребностей не выявлено, то напиши \"-\".\n",
        "Порядок отчета: в своем ответе предоставь только список потребностей (или  \"-\") в виде строки с разделителями (запятые).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tk5wHfP9HhTV"
      },
      "outputs": [],
      "source": [
        "#@title 2. Выделение в последнем сообщении менеджера названных им преимуществ\n",
        "name_benefits_extractor = 'Спец по озвученным преимуществам'\n",
        "model_benefits_extractor = MODEL\n",
        "temperature_benefits_extractor = 0.2\n",
        "verbose_benefits_extractor = 0\n",
        "system_prompt_benefits_extractor='''\n",
        "Ты лучший специалист по контролю качества отдела продаж и отлично умеешь находить в ответе менеджера\n",
        "названные менеджером преимущества обучения в университете искусственного интеллекта (сокр УИИ).\n",
        "У тебя для анализа есть Предыдущий ответ менеджера отдела продаж.\n",
        "Ты всегда очень строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_benefits_extractor = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Предыдущий ответ Менеджера отдела продаж, найди в нем названные преимущества (если они есть) и напиши их;\n",
        "Ничего не придумывай от себя, если преимущества не найдены, то напиши  \"-\".\n",
        "Порядок отчета: в своем ответе предоставь только список преимуществ (или  \"-\") в виде строки с разделителями (запятые).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ag09jt4iH3EC"
      },
      "outputs": [],
      "source": [
        "#@title 3. Выделение в последнем сообщении клиента озвученных им возражений\n",
        "name_objection_detector = 'Спец по возражениям'\n",
        "model_objection_detector = MODEL\n",
        "temperature_objection_detector = 0.2\n",
        "verbose_objection_detector = 0\n",
        "system_prompt_objection_detector = '''\n",
        "Ты - лучший специалист отдела продаж, специализирующийся на продаже курсов обучения искусственному интеллекту.\n",
        "Ты знаешь, что открытое возражение  - это явное заявление со стороны клиента о том, что его не устраивает и\n",
        "что может быть преградой для приобретения курсов обучения, а просьбы клинета не являются возражениями.\n",
        "Твоя задача - тщательно выявлять открытые возражения в Вопросе клиента.\n",
        "Ты всегда строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_objection_detector = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Вопрос клиента и выдели открытые возражения, которые он высказывает (если они есть).\n",
        "Примеры возражений могут включать в себя: \"дорого\", \"мне не хватит знаний/опыта\",\n",
        "\"мне не хватит времени на учебу\", \"слышал плохие отзывы\", \"наполнение\", \"все только обещают\" и т.п.\n",
        "В своем ответе укажи все выделенные открытые возражения клиента, соблюдая ту же последовательность, в какой они были\n",
        "высказаны в его вопросе. Ничего не придумывай от себя: если возражений  не найдено, то в своем ответе напиши \"-\".\n",
        "Порядок отчета: в свой ответ включи только список выделенных открытых возражений клиента (или  \"-\") в виде строки с разделителями (запятые).\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MjKO4aQEI8xJ"
      },
      "outputs": [],
      "source": [
        "#@title 4. Выделение в последнем сообщении менеджера отработки возражений клиента\n",
        "name_resolved_objection_detector = 'Спец по отработанным возражениям'\n",
        "model_resolved_objection_detector = MODEL\n",
        "temperature_resolved_objection_detector = 0.2\n",
        "verbose_resolved_objection_detector = 0\n",
        "\n",
        "system_prompt_resolved_objection_detector = '''\n",
        "Ты лучший специалист по контролю качества отдела продаж и отлично умеешь выявлять как Менеджер отдела продаж отработал возражения клиента.\n",
        "У тебя для анализа есть Предыдущий ответ Менеджера отдела продаж.\n",
        "Твоя задача - тщательно выявлять отработал ли Менеджера отдела продаж возражения в своем ответе клиенту.\n",
        "Ты всегда очень строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_resolved_objection_detector = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Предыдущий ответ Менеджера отдела продаж и найди в нем отработки возражений (если они есть) и напиши их.\n",
        "Ничего не придумывай от себя: если отработки возражений  не найдено, то напиши \"-\".\n",
        "Порядок отчета: в своем ответе предоставь только список отработок возражений (или \"-\") в виде строки с разделителями (запятые).\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oDz-9nTkJVTI"
      },
      "outputs": [],
      "source": [
        "#@title 5. Выделение в последнем сообщении менеджера названных им тарифов и цен\n",
        "name_tariff_detector = 'Спец по тарифам'\n",
        "model_tariff_detector = MODEL\n",
        "temperature_tariff_detector = 0.1\n",
        "verbose_tariff_detector = 0\n",
        "system_prompt_tariff_detector = '''\n",
        "Ты - аналитик по тарифам, ты прекрасно умеешь находить точное упоминание о тарифе в тексте.\n",
        "У тебя есть закрытый Перечень тарифов: [\"базовый тариф\", \"продвинутый тариф\", \"основной тариф\", \"расширенный тариф\", \"новый тариф\", \"фреймворки\", \"ChatGPT\"].\n",
        "У тебя для анализа есть Предыдущий ответ менеджера отдела продаж.\n",
        "Ты всегда очень строго следуешь порядку отчета.\n",
        "'''\n",
        "instructions_tariff_detector = '''\n",
        "Давай действовать последовательно:\n",
        "Проанализируй Предыдущий ответ менеджера отдела продаж, и найди в нем тарифы из Переченя тарифов и напиши их;\n",
        "если в ответе менеджера содержится упоминание о ценах, добавь их тоже в список.\n",
        "Ничего не придумывай от себя: если Предыдущий ответ менеджера отдела продаж не содержит упоминаний о тарифах или ценах,то напиши \"-\".\n",
        "Порядок отчета: в своем ответе предоставь только список найденных тарифов и цен (или \"-\") в виде строки с разделителями (запятые) без объяснений.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2kh_CODJ8vJ"
      },
      "source": [
        "### Функция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BhBSTLsZmi-X"
      },
      "outputs": [],
      "source": [
        "def extract_entity_from_statement(name, system, instructions, question, history,temp=0, verbose=0, model=MODEL):\n",
        "    if verbose: print('\\n==================\\n')\n",
        "    if verbose: print(f'{bcolors.OKBLUE}{bcolors.BOLD}Вопрос клиента: {question}{bcolors.ENDC}')\n",
        "    if name not in ['Спец по потребностям', 'Спец по возражениям'] and len(history):  # эти спецы анализируют только вопрос пользователя\n",
        "      history_content = history[-1]   # берем только один последний ответ Менеджера в истории\n",
        "    else:\n",
        "      history_content = 'сообщений нет'\n",
        "    if verbose: print(f'{bcolors.BGCYAN}Предыдущий ответ Менеджера отдела продаж:{bcolors.ENDC}\\n==================\\n',\n",
        "                         history_content)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f\"{instructions}\\n\\nВопрос клиента:{question}\\n\\nПредыдущий ответ Менеджера отдела продаж:\\n{history_content}\\n\\nОтвет: \"}\n",
        "    ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    answer = completion.choices[0].message.content\n",
        "    if verbose: print('\\n==================\\n')\n",
        "    if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print('\\n==================\\n')\n",
        "    if verbose:\n",
        "      print(f'{bcolors.GREEN}{bcolors.BOLD}Ответ {name}:{bcolors.ENDC}\\n',\n",
        "            f'{bcolors.GREEN}{answer}{bcolors.ENDC}')\n",
        "    return completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuM8rU70KS0B"
      },
      "source": [
        "## spez_user_question - узкий специалист для генерации ответа\n",
        "\n",
        "вызываются диспетчером-маршрутизатором готовят свою специализированную часть для того, чтобы старший менеджер но основе этих материалов сформировал проактивный ответ клиенту.\n",
        "\n",
        "В распоряжении узких специалистов: База знания, контекст - ключи диалога, Хронология предыдущих сообщений диалога, точное саммари (отчет по выявленным и отработанным ранее сущностям)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIa-O9GLMlcG"
      },
      "source": [
        "### Параметры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9es2DhD2TDbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. 'Обработчик_возражений'\n",
        "name_spez2 = 'Обработчик_возражений'\n",
        "model_spez2 = MODEL\n",
        "temperature_spez2 = 0.1\n",
        "verbose_spez2 = 0\n",
        "system_prompt_spez2 = '''Вы лучший специалист по отработке возражений клиента. Вы работаете в Университете (УИИ), который продает курсы обучения нейронным сетям и программированию.\"\n",
        "Вы знаете, что отработка возражения - это процесс убеждения с помощью аргументов,\n",
        "точных фактов и психологических приемов, которые помогают завуалированно донести до клиента мысль, что курсы ему нужны.\n",
        "Вы знаете, что отработка возражений не имеет ничего общего с давлением: продавец не манипулирует, а показывает как удовлетворить потребности клинета с помощью продукта.\n",
        "У Вас есть Точное саммари с отчетом о уже выявленных и уже отработанных возражениях клиента.\n",
        "Вы всегда последовательно, шаг за шагом и убедительно отрабатываете возражения клиента.\n",
        "При отработке возражения вы всегда следуете Хронологии предыдущих сообщений диалога чтобы сделать Ваш ответ логичным этой Хронологии.\n",
        "Вы всегда очень строго следуете порядку отчета.\n",
        "'''\n",
        "instructions_spez2 = '''\n",
        "Пожалуйста, проанализируйте запрос клиента и напишите убедительную и качественную отработку возражения клиента.\n",
        "Отработку пишите строго на основании информации из Базы знаний, ничего не придумывайте от себя: если подходящей информации в Базе знаний нет,\n",
        "напишите, что вопрос не связан с УИИ.\n",
        "Порядок отчета: в свой ответ выведите только отработку возражения.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3_p_2wMwl1lU",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2. 'Спец_по_презентациям'\n",
        "name_spez3 = 'Спец_по_презентациям'\n",
        "model_spez3 = MODEL\n",
        "temperature_spez3 = 0\n",
        "verbose_spez3 = 0\n",
        "system_prompt_spez3 = '''Вы - лучший специалист по презентации продукта и компании Университет искусственного интеллекта (сокр. УИИ),\n",
        "занимающейся продажей обучения. Ваш стиль общения деловой и очень краткий.\n",
        "Ваша цель: сделать убедительную и качественную презентацию по запросу клиента (запрос может быть о курсах/программах обучения, стоимости, об УИИ).\n",
        "Ваши презентации всегда основаны на Вопросе клиента, его потребностях и желаниях, Вы всегда следуете логике Хронологии предыдущих сообщений диалога.\n",
        "Вам запрещено повторять в своем ответе то, о чем уже говорилось в Хронологии предыдущих сообщений диалога.\n",
        "Вы никогда не используете шаблонный скриптовый вариант презентации, всегда делаете её в неформальной форме.\n",
        "Вы всегда строго следуете требованиям к порядку отчета.\n",
        "'''\n",
        "\n",
        "instructions_spez3 = '''\n",
        "Давайте действовать по шагам:\n",
        "#Шаг1: Проанализируйте Хронологию предыдущих сообщений диалога, чтобы выявить общую логику и последовательность общения менеджера по продажам и клиента, а также чтобы НЕ повторяться в своей презентации.\n",
        "#Шаг2: Проанализируйте Вопрос клиента и Точное саммари чтобы выбрать контекст для презентации.\n",
        "#Шаг3: Учитывая логику Шага1 и контекст Шага2, сделайте убедительную и качественную презентацию, не повторяйте сказанное в Хронологии предыдущих сообщений диалога.\n",
        "Презентацию нужно делать на основании информации из Базы знаний, ничего не придумывайте от себя: если подходящей информации в Базе знаний нет,\n",
        "напишите, что вопрос не связан с УИИ.\n",
        "Порядок отчета: в свой ответ включите только презентацию из Шага3.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yk6bcKYVl1yE"
      },
      "outputs": [],
      "source": [
        "#@title 3. 'Zoom_Пуш'\n",
        "name_spez4 = 'Zoom_Пуш'\n",
        "model_spez4 = MODEL\n",
        "temperature_spez4 = 0.2\n",
        "verbose_spez4 = 0\n",
        "\n",
        "system_prompt_spez4 = '''\n",
        "Вы лучший эксперт по последовательности этапов, которые нужно пройти, чтобы записать клиента на встречу в Zoom с экспертом университета искусственного интеллекта (сокр УИИ).\n",
        "Запись на встречу в Zoom с экспертом состоит из нескольких строго последовательных этапов,\n",
        "Ваша обязанность сообщать секретарю, к какому этапу записи он должен перейти в переговорах с клиентом при записи клиента на встречу в Zoom.\n",
        "Вы строго следите за соблюдением последовательности этапов, описанной в Инструкции.\n",
        "Вы всегда строго следуете логике Хронологии предыдущих сообщений диалога и Инструкции.\n",
        "# Инструкция о последовательности этапов процесса записи на встречу с экспертом в Zoom:\n",
        "##Этап1: клиент готов обсуждать детали приобретения курса/программы обучения или клиент просит записать его на встречу с экспертом;\n",
        "##Этап2: менеджер по продажам предложил встречу с экспертом + клиент согласился на встречу, но конкретный день и время встречи еще не обсуждали;\n",
        "##Этап3: клиент и менеджер договорились о конкретном дне и времени встречи с экспертом, клиент выбрал удобное для себя время из предложенных менеджером интервалов;\n",
        "##Этап4: клиент указал свой номер телефона и e-mail.\n",
        "Вам запрещено менять последовательность этапов записи на встречу (Вы всегда последовательно переходите от первого этапа ко второму, от второго к третьему, от третьего к четвертому).\n",
        "Вы всегда строго следуете порядку отчета.\n",
        "'''\n",
        "instructions_spez4 = '''\n",
        "Давайте действовать последовательно:\n",
        "#Шаг1 Проанализируйте Хронологию предыдущих сообщений диалога и Вопрос клиента чтобы определить, на каком этапе последовательности записи на встречу экспертом находится клиент;\n",
        "#Шаг2 На основании Вашего анализа напишите свой ответ:\n",
        "##Шаг2.1 если вы считаете что отправлять клиента на встречу рано то напишите: 'не выявлено';\n",
        "##Шаг2.2 если клиент готов к встрече, но в Хронологии предыдущих сообщений диалога не найдены пройденные этапы процесса записи на встречу с экспертом то напишите: Этап1;\n",
        "##Шаг2.3 если по Хронологии предыдущих сообщений диалога Вы смогли определить на каком этапе находится процесс записи то в своем ответе напишите этот Этап, например: Этап2.\n",
        "Последовательность и описание этапов должны строго соответствовать Инструкции.\n",
        "Порядок отчета: в свой ответ напишите только результат #Шага2\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0vTwy3HHUTd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lS8Y3A5h91AA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 4. 'Спец_по_выявлению_потребностей'\n",
        "name_spez5 = 'Спец_по_выявлению_потребностей'\n",
        "model_spez5 = MODEL\n",
        "temperature_spez5 = 0.4\n",
        "verbose_spez5 = 0\n",
        "system_prompt_spez5 = '''\n",
        "Вы лучший менеджер по продажам с навыками NLP.\n",
        "Вы понимаете какие потребности клиента надо выявить, чтобы полностью понять желания и боли клиента,\n",
        "которые можно удовлетворить при помощи обучения в области искусственного интеллекта и программирования.\n",
        "Вы знаете, что важно выявить есть ли у клиента такие потребности: в трудоустройстве, в росте дохода,\n",
        "в возможности работать удаленно, развиваться в сфере IT, сменить деятельность, в карьерном росте, во фрилансе,\n",
        "в улучшении текущей позиции в компании, в развитии своего проекта (если он есть), в получении прибыли от своего\n",
        "проекта (если он есть), в увекательном хобби, в личностном развитии и другие.\n",
        "Вы понимаете, что нужно аккуратно и ненавязчиво выявить несколько разных потребностей и составляете свой ответ с этой целью.\n",
        "Ваша задача: сформулировать вопросы клиенту, которые помогут качественно выявить его потребности.\n",
        "Вы всегда очень строго следуете порядку отчета.\n",
        "'''\n",
        "instructions_spez5 = '''\n",
        "Давайте действовать по шагам:\n",
        "#Шаг1: Проанализируйте Точное саммари 'Раздел 1 Выявлены Потребности', найдите в нем уже выявленные потребности (ничего не придумывайте от себя);\n",
        "#Шаг2: Предположите три другие потребности, которых нет среди выявленных потребностей в Шаг1;\n",
        "#Шаг3: Учитывая, что выявление потребностей должно провоцировать дальнейший диалог и заинтересовывать клиента,\n",
        "для каждой потребности из Шаг2 напишите по одному вопросу для качественного выявления этой потребности. Ничего, кроме вопросов не пишите и не объясняйте.\n",
        "Порядок отчета: В свой ответ включите только список вопросов Шаг3, ничего кроме списка вопросов выводить не нужно.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "D6knpwLdH-4N",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 5. 'Спец_по_завершению'\n",
        "name_spez6 = 'Спец_по_завершению'\n",
        "model_spez6 = MODEL\n",
        "temperature_spez6 = 0.4\n",
        "verbose_spez6 = 0\n",
        "system_prompt_spez6 = '''\n",
        "Ты Василий, менеджер по продажам УИИ.\n",
        "Ты неплохо разбираешься в нейронных сетях и программировании в целом и очень хорошо знаешь, что УИИ предоставляет курсы и программы обучения в этой области.\n",
        "Вы общаетесь с клиентом о покупке курса.\n",
        "Ты завершаешь диалог и прощаешься с клиентом.\n",
        "Твоя задача: отвечать когда диалог подошел к завершению - когда клиент прекращает задавать новые вопросы или не написал в своём сообщении ничего кроме таких фраз как “спасибо”, “понятно” или прощальных фраз, или задал вопрос не по теме.\n",
        "Ты знаешь, что прощальные фразы - это фразы или выражения которые используются для окончания общения или разговора.\n",
        "Прощальные фразы часто служат для передачи понимания, согласия, благодарности или желания прощания (например пока, до свидания, до скорой встречи, всего наилучшего, до новых встреч).\n",
        "Прощальные фразы имеют различные тон и уровень формальности, и выбор конкретной фразы зависит от контекста.\n",
        "Ты всегда четко следуешь Хронологии предыдущих сообщений диалога, чтобы сделать свой ответ логичным этой Хронологии.\n",
        "Тебе запрещено задавать клиенту вопросы. Тебе запрещено отвечать на запросы клиента.\n",
        "Твоя задача написать клиенту сообщение завершающее диалог, подтвердить договоренности о встрече (если были) и попрощаться с клиентом.\n",
        "'''\n",
        "instructions_spez6 = '''Проанализируй Вопрос клиента и Хронологию предыдущих сообщений диалога: если клиент задал вопрос, который не связан с нейронными сетями, IT, обучением в УИИ, в своем ответе тебе нужно написать, что ты не можешь отвечать\n",
        "на вопросы, не связанные с обучением в УИИ, в остальных случаях напиши клиенту сообщение завершающее диалог, подтверди договоренности о встрече и попрощайся с клиентом.\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-TE4WcvPGhn"
      },
      "source": [
        "### Функция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Z7e1o9m_-dha"
      },
      "outputs": [],
      "source": [
        "\n",
        "def spez_user_question(name, system, instructions, question, summary_history, summary_exact, base_topicphrase, search_index, temp=0, verbose=0, k=num_chunks, model=MODEL):\n",
        "    if name in [\"Zoom_Пуш\", \"Спец_по_завершению\"]:\n",
        "      docs_content = ''\n",
        "    else:\n",
        "      knowledge_base = search_index.similarity_search(base_topicphrase, k=k)\n",
        "      docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n==================\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "\n",
        "         Вопрос клиента:{question}\n",
        "\n",
        "         Хронология предыдущих сообщений диалога: {summary_history}\n",
        "\n",
        "         Точное саммари: {summary_exact}\n",
        "\n",
        "         База Знаний: {docs_content}'''}\n",
        "    ]\n",
        "    if verbose: print('\\n==================\\n')\n",
        "    if verbose: print(f'{bcolors.BGCYAN}Вопрос клиента:{bcolors.ENDC}', question)\n",
        "    if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "                         summary_history)\n",
        "    if verbose: print(f'{bcolors.BGYELLOW}Саммари точное:{bcolors.ENDC}\\n==================\\n',\n",
        "                         summary_exact)\n",
        "    if verbose: print(f'{bcolors.BGGREEN}База знаний:{bcolors.ENDC}\\n==================\\n', docs_content)\n",
        "\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    answer = completion.choices[0].message.content\n",
        "    try:\n",
        "      answer = answer.split(': ')[1]+ ' '\n",
        "    except:\n",
        "      answer = answer\n",
        "    answer = answer.lstrip('#3')\n",
        "    if verbose: print(f'\\n==================')\n",
        "    if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print('\\n==================\\n')\n",
        "    if verbose: print(f'{bcolors.RED}{bcolors.BOLD}Ответ {name}:{bcolors.ENDC}\\n',\n",
        "                      f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    return completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJywUK05TeH7"
      },
      "source": [
        "### Конфигурация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xgfzoaVTRrOa"
      },
      "outputs": [],
      "source": [
        "spez_config ={\n",
        "    'Обработчик_возражений': {\n",
        "        'name':name_spez2,\n",
        "        'system':system_prompt_spez2,\n",
        "        'instructions':instructions_spez2,\n",
        "        'k': num_chunks,\n",
        "        'temp':temperature_spez2,\n",
        "        'verbose': verbose_spez2,\n",
        "        'model':model_spez2,\n",
        "        },\n",
        "    'Спец_по_презентациям': {\n",
        "        'name':name_spez3,\n",
        "        'system':system_prompt_spez3,\n",
        "        'instructions':instructions_spez3,\n",
        "        'k': num_chunks,\n",
        "        'temp':temperature_spez3,\n",
        "        'verbose': verbose_spez3,\n",
        "        'model':model_spez3,\n",
        "        },\n",
        "    'Zoom_Пуш': {\n",
        "        'name':name_spez4,\n",
        "        'system':system_prompt_spez4,\n",
        "        'instructions':instructions_spez4,\n",
        "        'k': num_chunks,\n",
        "        'temp':temperature_spez4,\n",
        "        'verbose': verbose_spez4,\n",
        "        'model':model_spez4,\n",
        "        },\n",
        "    'Спец_по_выявлению_потребностей': {\n",
        "        'name':name_spez5,\n",
        "        'system':system_prompt_spez5,\n",
        "        'instructions':instructions_spez5,\n",
        "        'k': num_chunks,\n",
        "        'temp':temperature_spez5,\n",
        "        'verbose': verbose_spez5,\n",
        "        'model':model_spez5,\n",
        "        },\n",
        "    'Спец_по_завершению': {\n",
        "        'name':name_spez6,\n",
        "        'system':system_prompt_spez6,\n",
        "        'instructions':instructions_spez6,\n",
        "        'k': num_chunks,\n",
        "        'temp':temperature_spez6,\n",
        "        'verbose': verbose_spez6,\n",
        "        'model':model_spez6,\n",
        "        }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9qrgfUAPwoU"
      },
      "source": [
        "## user_question_router - Диспетчер-маршрутизатор\n",
        "\n",
        "модель определяет по контексту, Хронологии предыдущих сообщений диалога и точному саммари каких узких специалистов нужно привлечь для подготовки материалов для проактивного ответа Старшего менеджера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vj73tRZwtTVM"
      },
      "outputs": [],
      "source": [
        "#@title Параметры\n",
        "name_router = 'Диспетчер-маршрутизатор'\n",
        "model_router = MODEL\n",
        "temperature_router = 0\n",
        "verbose_router = 0\n",
        "\n",
        "# если уже выявлено 4 потребности, то больше потребности вывлять не нужно.\n",
        "# это можно сделать в промпте, но он перегружен. Поэтому ограничим вызов спеца по выявлению программно:\n",
        "system_prompt_router ='''\n",
        "Ты идеально справляешься со своей задачей: ты определяешь к каким специалистам нужно обратиться, чтобы корректно сформировать ответ клиенту.\n",
        "Ты знаешь, что можно обратиться только к специалистам из Перечня: '''\n",
        "instructions_router ='''\n",
        "Пожалуйста, будем действовать по шагам:\n",
        "#Шаг1: проанализируйте Вопрос клиента и Хронологию предыдущих сообщений диалога чтобы быть в контексте;\n",
        "#Шаг2: проанализируйте Точное саммари - оно содержит кратко уже выявленные потребности, отработанные возражения и презентованные тарифы;\n",
        "#Шаг3: опираясь на анализ Шаг1 и Шаг2 напиши список специалистов для ответа клиенту.\n",
        "Отвечай, пожалуйста, точно, и ничего не придумывай от себя.\n",
        "Список специалистов может быть пустым [] если нет необходимости, или же 1 специалист, или несколько, или все.\n",
        "Порядок отчета: напиши только список специалистов из Шаг3 в формате list python.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WA1UVyvE97xh"
      },
      "outputs": [],
      "source": [
        "#@title Функция\n",
        "def user_question_router(name, system, instructions, question, summary_history, summary_exact, temp=0, verbose=0, model=MODEL, needs_lst=[]):\n",
        "    if verbose: print('\\n==================\\n')\n",
        "    if verbose: print(f'{bcolors.BGCYAN}Вопрос клиента:{bcolors.ENDC}', question)\n",
        "    if verbose: print('Саммари диалога:\\n==================\\n',\n",
        "                         summary_history)\n",
        "    if verbose: print(f'{bcolors.BGYELLOW}Саммари точное:{bcolors.ENDC}\\n==================\\n',\n",
        "                         summary_exact)\n",
        "\n",
        "\n",
        "    if needs_lst and len(needs_lst) > 5:\n",
        "      system +=''' [\"Обработчик_возражений\", \"Спец_по_презентациям\", \"Zoom_Пуш\", “Спец_по_завершению”]. Ты знаешь, за что отвечает каждый специалист:\n",
        "  #1 Обработчик_возражений:  этот специалист участвует в ответе клиенту если:\n",
        "  #1.1 клиент высказал возражение или сомнение;\n",
        "  #1.2 клиент чем-то недоволен или не все устраивает в продукте;\n",
        "  #2 Спец_по_презентациям: этот специалист участвует в ответе клиенту если клиент выразил заинтересованность курсами, программами\n",
        "  и нужно презентовать курс по нейронным сетям и программированию или какую-то его часть, а также презентовать компанию университет искусственного\n",
        "  интеллекта (сокр УИИ), если при этом в Хронологии предыдущих сообщений диалога он это уже презентовал, то повторно презентовать запрещено;\n",
        "  #3 Zoom_Пуш: этот специалист участвует в ответе клиенту когда:\n",
        "  #3.1 клиент готов к покупке курса и нужно звать клиента на встречу с экспертом для оформления покупки;\n",
        "  #3.2 клиент обсуждает день и время встречи с экспертом в Zoom;\n",
        "  #3.3 клиент предоставляет свои контактные данные для отправки приглашения на встречу в Zoom;\n",
        "  #4 Спец_по_завершению: этот специалист участвует в ответе клиенту в самом конце диалога, его задача отвечать когда пользователь дает понять,\n",
        "  что завершает диалог и больше не намерен ничего спрашивать, например: \"спасибо\",\"все понтяно\",\"хорошо\", \"ладно\" и прочие утвердительные\n",
        "  выражения логически завершающие общение.'''\n",
        "    else:\n",
        "      system +=''' [\"Спец_по_выявлению_потребностей\", \"Обработчик_возражений\", \"Спец_по_презентациям\", \"Zoom_Пуш\",  “Спец_по_завершению”]. Вот описание специалистов:\n",
        "  #1 Спец_по_выявлению_потребностей: этот специалист всегда участвует в ответе;\n",
        "  #2 Обработчик_возражений:  этот специалист участвует в ответе клиенту если:\n",
        "  #2.1 клиент высказал возражение или сомнение;\n",
        "  #2.2 клиент чем-то недоволен или не все устраивает в продукте;\n",
        "  #3 Спец_по_презентациям: этот специалист участвует в ответе клиенту если клиент выразил заинтересованность курсами, программами\n",
        "  и нужно презентовать курс по нейронным сетям и программированию или какую-то его часть, а также презентовать компанию университет искусственного\n",
        "  интеллекта (сокр УИИ), если при этом в Хронологии предыдущих сообщений диалога он это уже презентовал, то повторно презентовать запрещено;\n",
        "  #4 Zoom_Пуш: этот специалист участвует в ответе клиенту когда:\n",
        "  #4.1 клиент говорит что курс или программа обучения ему подходит - чтобы позвать клиента на встречу с экспертом;\n",
        "  #4.2 клиент выражает готовность к покупке курса или программы обучения - чтобы позвать клиента на встречу с экспертом для оформления покупки;\n",
        "  #4.2 клиент обсуждает день и время встречи с экспертом в Zoom чтобы договориться о встрече;\n",
        "  #4.3 клиент предоставляет свои контактные данные для отправки приглашения на встречу в Zoom;\n",
        "  #5 Спец_по_завершению: этот специалист участвует в ответе клиенту в самом конце диалога, его задача отвечать когда пользователь дает понять,\n",
        "  что завершает диалог и больше не намерен ничего спрашивать, например: \"спасибо\",\"все понтяно\",\"хорошо\", \"ладно\" и прочие утвердительные\n",
        "  выражения логически завершающие общение.'''\n",
        "    system +='''\n",
        "  Твоя задача: определить по сообщению клиента, на основании твоих знаний, Точного саммари и Хронологии предыдущих сообщений диалога каких специалистов из Перечня надо выбрать,\n",
        "  чтобы они участвовали в ответе клиенту. Ты всегда очень строго следуешь требованиям к порядку отчета.'''\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                      \\n\\nВопрос клиента:{question}\n",
        "                                      \\n\\nХронология предыдущих сообщений диалога: {summary_history}\n",
        "                                      \\n\\nСаммари точное: {summary_exact}\n",
        "                                      \\n\\nОтвет: '''}\n",
        "    ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "    answer = completion.choices[0].message.content\n",
        "    if verbose: print(f'\\n==================')\n",
        "    if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print('\\n==================\\n')\n",
        "    if verbose: print(f'{bcolors.RED}{bcolors.BOLD}Ответ {name}:{bcolors.ENDC}\\n',\n",
        "                      f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    if verbose: print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    #print(f'{bcolors.RED}{answer}{bcolors.ENDC}')\n",
        "    return completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IZ8mY8xSWhg"
      },
      "source": [
        "## senior_answer - генерация старшим менеджером проактивного ответа на основании данных узких специалистов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aX_dms8m1jzG"
      },
      "outputs": [],
      "source": [
        "#@title Параметры\n",
        "name_senior = 'Старший менеджер по продажам'\n",
        "model_senior = MODEL\n",
        "temperature_senior = 0.2\n",
        "verbose_senior = 0\n",
        "num_fragments_base_senior = num_chunks\n",
        "system_prompt_senior = '''\n",
        "#1 Кто вы такой: Вы человек, мужчина. Вы лучший старший менеджер отдела продаж. Вы работаете в Университете Искусственного интеллекта (сокр УИИ),\n",
        "который продает курсы обучения нейронным сетям и языку программирования python.\n",
        "Вы неплохо разбираетесь в нейронных сетях и программировании в целом и очень хорошо знаете, какие курсы и программы обучения предоставляет УИИ.\n",
        "При формировании ответа всегда следуете логике Хронологии предыдущих сообщений диалога чтобы Ваш ответ клиенту был логичным и последовательным и\n",
        "в первую очередь ориентируетесь на Ответы узких специалистов: '''\n",
        "\n",
        "instructions_senior = '''\n",
        "Пожалуйста, давайте думать последовательно. Вам нужно решить эти задачи:\n",
        "#1 задача: проанализируйте Ответы узких специалистов - это информация на которую Вы опираетесь при ответе;\n",
        "#2 задача: проанализируйте Хронологию предыдущих сообщений диалога чтобы написать свой ответ последовательным и логичным этой хронологии;\n",
        "#3 задача: проанализируйте Точное саммари, чтобы понять, какие  были высказаны потребности, возражения и какие возражения были уже отработаны в ходе диалога и не повторяться;\n",
        "#4 задача:  опираясь на свой анализ в задачах 1-3 и следуя Инструкциям напишите логичный, краткий, последовательный ответ клиенту, имитируя ответ реального человека следуя порядку отчета:\n",
        "в своем ответе не говорите клиенту о своих целях; всегда пишите текст в неформальной форме, не называйте клиента клиентом, если в Хронологии предыдущих сообщений диалога\n",
        "есть информация об имени клиента, то добавьте имя клиента в свой ответ.\n",
        "При формировании своего ответа Вам запрещено повторять тезисы, которые уже были высказаны в Хронологии предыдущих сообщений диалога.'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hl5I8ESpP_82"
      },
      "outputs": [],
      "source": [
        "#@title Функция\n",
        "def senior_answer(name, system, instructions, question, output_spez,\n",
        "                                   summary_history, base_topicphrase, search_index, summary_exact, temp=0,\n",
        "                                   verbose=0, k=num_chunks, model=MODEL, spez_list = []):\n",
        "    # дозаполним system по набору спецов\n",
        "    if 'Спец_по_завершению'  in spez_list:\n",
        "        system += \"Спец_по_завершению.\"\n",
        "    else:\n",
        "        system += '''Обработчик_возражений, Спец_по_презентациям, Zoom_пуш, Спец_по_выявлению_потребностей.\n",
        "#2 Ваша цель общения: в течение всего диалога выявить потребности клиента, закрыть все возражения клиента и в итоге назначить встречу клиента с экспертом для обсуждения деталей приобретения курса в соответствии с выявленными потребностями.\n",
        "Вы всегда строго следуете Инструкциям и порядку отчета.\n",
        "#3 Инструкция как отвечать на вопрос клиента:\n",
        "##3.1 При формировании своего ответа вы всегда следуете логике Хронологии предыдущих сообщений диалога и опираетесь на Ответы узких специалистов.\n",
        "##3.2 Презентацию делайте только в том случае, если клиент попросит рассказать о курсе\\обучении\\университете или она закрывает какие-то потребности, презентуйте опираясь на ответ Спец_по_презентациям;\n",
        "##3.3 Если у вас есть ответ Обработчик_возражений, то закройте возражения, опираясь на ответ Обработчик_возражений;\n",
        "##3.4 Вы знаете, что Вам важно закрыть все возражения клиента;\n",
        "##3.5 В ответе Вам категорически запрещено говорить что Вы выясняете потребности и цели клиента;\n",
        "##3.6 Вам запрещено разговаривать на посторонние темы.\n",
        "#4 Инструкция как отвечать на посторонние темы: если в Ответах узких специалистов написано, что вопрос не связан с УИИ, это значит, что нужно вежливо отказаться\n",
        "отвечать на вопросы на посторонние темы и уточнить, есть ли у клиента вопросы касающиеся курсов, программ обучения в УИИ или самого универститета.'''\n",
        "\n",
        "    if 'Zoom_Пуш'  in spez_list:\n",
        "        system += '''\n",
        "#5 Инструкция как звать клиента на встречу с экспертом в Zoom:\n",
        "##5.1 Проанализируйте ответ специалиста Zoom_Пуш: он должен сообщить Вам текущий этап процесса записи на встречу с экспертом (например, \"Этап2\").\n",
        "##5.2 Если в ответе Zoom_Пуш нет текущего этапа, то пока назначать встречу с экспертом рано;\n",
        "##5.3 Если в ответе Zoom_Пуш есть текущий этап, найдите в Таблице этапов Инструкцию, соответствующую текущему этапу и подготовте свой ответ строго в полном соответствии с этой инструкцией.\n",
        "Ничего не придумывайте от себя, строго следуйте инструкции текущего этапа:\n",
        "###Таблица этапов:\n",
        "|Этап| Инструкция|\n",
        "|Этап1| Аргументируйте на основании потребностей клиента зачем ему нужно согласиться на Zoom встречу и задайте вопрос подтверждающий согласие клиента на участие во встрече;|\n",
        "|Этап2| Предложите клиенту на выбор три конкретных варианта временных промежутков для встречи (например, \"Завтра в 16:00, Завтра в 20:00, Послезавтра в 10:00\" и тп) и попросите клиента выбрать (из предложенных) подходящее;|\n",
        "|Этап3| Запросите номер телефона и почту и аргументируйте что телефон нужен Вам чтобы отправить ссылку на встречу клиенту;|\n",
        "|Этап4| Поблагодарите клиента за приятный диалог и напишите о том что встреча назначена на такой-то день и такое-то время|\n",
        "Вы обязаны в точности следовать инструкции текущего этапа записи на встречу, ничего не исключайте из нее и не добавляйте от себя.'''\n",
        "    system += '''\n",
        "Вы всегда строго следуете порядку отчета'''\n",
        "\n",
        "    # дозаполним instructions по набору спецов\n",
        "    if 'Спец_по_завершению'  not in spez_list:\n",
        "      if 'Спец_по_выявлению_потребностей' in spez_list:\n",
        "        instructions += '''\n",
        "#5 задача:  Опираясь на свой анализ выберите только один вопрос из ответа Спец_по_выявлению_потребностей, которого нет в Хронологии предыдущих сообщений диалога и он лучше всего подходит\n",
        "логике Хронологии предыдущих сообщений диалога.'''\n",
        "      else:\n",
        "        instructions += '''\n",
        "#5 задача: Опираясь на свой анализ задайте вопрос, который должен способствовать продолжению диалога, продолжая логику Хронологи предыдущих сообщений диалога.'''\n",
        "      instructions += '''  Не объясняйте свой выбор и ничего не комментируйте, не поясняйте из ответа каких специалистов Вы формируете свой ответ.\n",
        "Порядок отчета: В Вашем ответе должен быть только ответ клиенту (Задача 4) + только вопрос клиенту (Задача 5) (без пояснений и комментариев).'''\n",
        "    else:\n",
        "      instructions += '''\n",
        "В свой ответ только включите ответ Спец_по_завершению.\n",
        "Порядок отчета: В Вашем ответе должен быть только ответ клиенту.\n",
        "'''\n",
        "#    knowledge_base = search_index.similarity_search(base_topicphrase, k=2)\n",
        "#    docs_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n=====\\n' + doc.page_content + '\\n' for doc in knowledge_base]))\n",
        "    output_spez_content = \"\\n=====\\n\".join(output_spez)\n",
        "    if verbose:\n",
        "      print(f'{bcolors.BGGREEN}Ответы узких специалистов:{bcolors.ENDC}{output_spez_content}\\n')\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\n",
        "                                    \\nВопрос клиента: {question}\n",
        "                                    \\nХронология предыдущих сообщений диалога: {summary_history}\n",
        "                                    \\nСаммари точное: {summary_exact}\n",
        "                                    \\nОтветы узких специалистов: {output_spez_content}\n",
        "\n",
        "                                    \\nОтвет: '''}\n",
        "    ]\n",
        "#                                    \\nДополнительная информация: {docs_content}\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    if verbose:\n",
        "      print(f'{bcolors.OKBLUE}{bcolors.BOLD}Ответ {name}:{bcolors.ENDC}\\n',\n",
        "            f'{bcolors.OKBLUE}{completion.choices[0].message.content}{bcolors.ENDC}')\n",
        "\n",
        "    return completion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdwkAO5yTNND"
      },
      "source": [
        "## Стилист"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nxPLX91xHq1Q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Параметры\n",
        "name_stilist = 'Стилист'\n",
        "model_stilist = MODEL\n",
        "temperature_stilist = 0.2\n",
        "verbose_stilist = 0\n",
        "system_prompt_stilist = '''\n",
        "Вы молодой человек, мужчина, общаетесь интересно для собеседника,\n",
        "Вы любите Университет искусственного интеллекта (сокр УИИ) и Вам очень нравится\n",
        "заниматься нейронными сетями, так же Вы отличный писатель. У Вас очень грамотная речь и Вы избегаете употреблять\n",
        "однокоренные слова в одном предложении и избегаете употреблять одинаковые слова в соседних предложениях.\n",
        "Вы знаете, что Стилизация - это перефразирование текста под  Ваш стиль с сохранением его смысла и посыла.\n",
        "Ваш стиль является человеческим, кратким и убедительным, Вы не используете клише и шаблонные выражения а также обращения, такие как \"Уважаемый...\", \"Клиент\" и т.п.\n",
        "Вы всегда соблюдаете 5 правил.\n",
        "Ваша задача: стилизовать Исходный текст так, чтобы создавалось 100% имитация диалога с реальным человеком.\n",
        "'''\n",
        "instructions_stilist = '''\n",
        "Давайте подумаем по шагам:\n",
        "#Шаг1: проанализируйте Исходный текст;\n",
        "#Шаг2: перефразируйте Исходный текст в Вашем стиле, соблюдая ВСЕ 5 правил на 100%:\n",
        "#2.1 если в Исходном тексте есть обращения к клиенту “на ты”, то замените их все обращениями “на Вы”;\n",
        "#2.2 если в Исходном тексте есть пожелания удачи и успехов, то исключите их из своего ответа;\n",
        "#2.3 если в Исходном тексте есть закрытые вопросы, то их перефразируйте в открытые;\n",
        "#2.4 Вам запрещено называть клиента \"клиент\"\n",
        "#2.5 Вам запрещено подписываться \"С уважением, Университет искусственного интеллекта\" (или похожим образом)\n",
        "Порядок отчета: в свой ответ включите только стилизованный текст.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oOKUTxupw1mw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Функция\n",
        "def stilizator_answer(name, system, instructions, answers_content, temp=0, verbose=0, model=MODEL):\n",
        "\n",
        "    if verbose: print('==================')\n",
        "    if verbose: print(f'{bcolors.BGCYAN}Текст для стилизации:{bcolors.ENDC}\\n{answers_content}')\n",
        "    user_assist = f'''{instructions}\\n\\nИсходный текст: Кира, я рад, что ты заинтересовалась нашими курсами. Наши программы обучения позволят тебе погрузиться в мир искусственного интеллекта с самого начала обучения.\n",
        "        Ты сможешь принять участие в реальных проектах уже с начала обучения, что поможет тебе получить ценный опыт и умения, необходимые для успешной карьеры в этой области.\n",
        "        Какие области твоей жизни ты бы хотела улучшить с помощью обучения в области искусственного интеллекта?\n",
        "\n",
        "        Ответ:\n",
        "    '''\n",
        "    user_assist2 = f'''{instructions}\\n\\nИсходный текст: У нас в УИИ самая обширная база учебного контента по искусственному интеллекту, включая 174 темы, что значительно\n",
        " превосходит количество учебных материалов у конкурентов, включая SkillBox. Какие возможности для трудоустройства в сфере искусственного интеллекта и программирования Вас\n",
        " интересуют?\n",
        "        Ответ:\n",
        "    '''\n",
        "\n",
        "    messages = [\n",
        "\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user_assist},\n",
        "        {\"role\": \"assistant\", \"content\": '''Кира, я рад, что Вы заинтересовались нашими курсами. Наши образовательные программы позволят Вам окунуться в мир искусственного интеллекта с самого начала. Участвуя в реальных проектах уже на старте обучения, Вы сможете получить ценный опыт и необходимые умения для успешной карьеры в этой области. Что именно Вы хотели бы улучшить в своей жизни, изучая искусственный интеллект?'''},\n",
        "        {\"role\": \"user\", \"content\": user_assist2},\n",
        "        {\"role\": \"assistant\", \"content\": '''У нас в УИИ самая обширная база учебного контента по искусственному интеллекту, включая 174 темы, что значительно\n",
        " превосходит количество учебных материалов у конкурентов, включая SkillBox. Может быть Вас интересуют возможности для трудоустройства в сфере искусственного интеллекта и программирования?'''},\n",
        "        {\"role\": \"user\", \"content\": f'''{instructions}\\n\\nИсходный текст: {answers_content}\\n\\nОтвет: '''}\n",
        "    ]\n",
        "\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print('==================')\n",
        "    if verbose:\n",
        "      print(f'{bcolors.BGMAGENTA}Ответ {name}:{bcolors.ENDC}\\n',\n",
        "            f'{bcolors.HEADER}{completion.choices[0].message.content}{bcolors.ENDC}')\n",
        "\n",
        "    return completion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Очистка от приветствия"
      ],
      "metadata": {
        "id": "tT204QElOrBd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YRzg06NwUx7I",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Параметры:\n",
        "system_prompt_stilist1 = '''\n",
        "Ты отличный редактор текстов и лучше всех умеешь находить в тексте приветствие (приветственную фразу).\n",
        "Приветствие - это выражение приветствия или приветственное сообщение,\n",
        "которое отправляется или произносится в начале общения с кем-либо.\n",
        "Приветствие может быть формальным или неформальным, зависеть от культуры и контекста.\n",
        "Оно служит для демонстрации вежливости, дружелюбия и желания установить контакт с собеседником.\n",
        "Приветствия могут быть разными в различных языках и культурах, от простого 'привет' или 'здравствуйте'\n",
        "до более формальных или традиционных выражений.\n",
        "Твоя задача обработать Исходный текст следующим образом: проанализировать Исходный текст и если в нем есть приветствие, то удалить его.\n",
        "В свой ответ включи обработанный текст без приветствия.\n",
        "'''\n",
        "instructions_prompt_stilist1 = ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функция\n",
        "def del_hello(name, system, instructions, answers_content, temp=0, verbose=0, model=MODEL):\n",
        "\n",
        "    if verbose: print('==================')\n",
        "    if verbose: print(f'{bcolors.BGCYAN}Текст для стилизации:{bcolors.ENDC}\\n{answers_content}')\n",
        "    user_assist = '''\\n\\nИсходный текст: Добрый день, Кира, я готов рассказать Вам о курсе подробнее. Начнем с тарифов?\\n\\nОтвет:'''\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user_assist},\n",
        "        {\"role\": \"assistant\", \"content\":'''Кира, я готов рассказать Вам о курсе подробнее. Начнем с тарифов?'''},\n",
        "        {\"role\": \"user\", \"content\": f'''\\n\\nИсходный текст: {answers_content}\\n\\nОтвет: '''}\n",
        "    ]\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp\n",
        "    )\n",
        "\n",
        "    if verbose: print('\\n==================')\n",
        "    if verbose: print(f'{completion.usage.total_tokens} total tokens used (question-answer).')\n",
        "    if verbose: print('==================')\n",
        "    if verbose:\n",
        "      print(f'{bcolors.BGMAGENTA}Ответ {name}:{bcolors.ENDC}\\n',\n",
        "            f'{bcolors.HEADER}{completion.choices[0].message.content}{bcolors.ENDC}')\n",
        "\n",
        "    return completion"
      ],
      "metadata": {
        "id": "QaaQ35AdH6JR",
        "cellView": "form"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awdPdDx0Z_ZK"
      },
      "source": [
        "# Функции Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NazTMSkY8-Ur",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Общие функции\n",
        "# Функция загружает plane text из ГуглДока по URL-ссылке (url).\n",
        "# ГуглДок должен быть открыт для чтения всем, у кого есть ссылка\n",
        "def load_googledoc_by_url(url: str) -> str:\n",
        "        match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
        "        if match_ is None:\n",
        "            raise ValueError('Invalid Google Docs URL')\n",
        "        doc_id = match_.group(1)\n",
        "        response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
        "        response.raise_for_status()\n",
        "        return response.text\n",
        "\n",
        "# Функция подсчета токенов для модели эмбеддингов\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "# функция подсчета токенов в сообщении модели\n",
        "def num_tokens_from_messages(messages, model):\n",
        "      \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
        "      try:\n",
        "          encoding = tiktoken.encoding_for_model(model)\n",
        "      except KeyError:\n",
        "          encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "      if model in [\"gpt-4-1106-preview\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-1106\"]:  # note: future models may deviate from this\n",
        "          num_tokens = 0\n",
        "          for message in messages:\n",
        "              num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
        "              for key, value in message.items():\n",
        "                  num_tokens += len(encoding.encode(value))\n",
        "                  if key == \"name\":  # if there's a name, the role is omitted\n",
        "                      num_tokens += -1  # role is always required and always 1 token\n",
        "          num_tokens += 2  # every reply is primed with <im_start>assistant\n",
        "          return num_tokens\n",
        "      else:\n",
        "          raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}.\n",
        "          See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
        "\n",
        "\n",
        "# Функция разделения текста на чанки заданной длины (в токенах)\n",
        "def split_text(text, max_count, chunk_overlap):\n",
        "\n",
        "    # Функция для подсчета количества токенов во фрагменте для сплиттера RecursiveCharacterTextSplitter\n",
        "    def num_tokens(fragment):\n",
        "        return num_tokens_from_string(fragment, \"cl100k_base\")\n",
        "\n",
        "    num_levels = 3  # Число уровней заголовков, которые будем разделять сплиттером MarkdownHeaderTextSplitter\n",
        "\n",
        "    headers_to_split_on = [\n",
        "    (f\"{'#' * i}\", f\"H{i}\") for i in range(1, num_levels + 1)\n",
        "    ]\n",
        "    # сначала разделим с помощью MarkdownHeaderTextSplitter\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "    fragments = markdown_splitter.split_text(text)\n",
        "\n",
        "\n",
        "    # дальше будем делить делить каждый полученный чанк вторым сплиттером RecursiveCharacterTextSplitter\n",
        "    # 1. для того, чтобы быть уверенным в размере полученного чанка\n",
        "    # 2. база знаний размечена так, что заголовки не повторяются в тексте разделов, мы это исправим принудительно:\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=max_count, chunk_overlap=0, length_function=num_tokens)\n",
        "\n",
        "    source_chunks = []\n",
        "\n",
        "    # Обработаем каждый фрагмент текста, полученный после MarkdownHeaderTextSplitter\n",
        "    for fragment in fragments:\n",
        "    # MarkdownHeaderTextSplitter сохранил иерархию заголовков в Метаданных - вытащим ее\n",
        "      level = 0\n",
        "      headers = ['','','','']\n",
        "      for j in range(1, num_levels + 1):\n",
        "        header_key = f'H{j}'\n",
        "        if header_key in fragment.metadata: level, headers[j-1] = j, fragment.metadata[header_key]\n",
        "      header_string = ' '.join([f\"{'#' * i} {header}\" for i, header in enumerate(headers[:level], start=1)])\n",
        "\n",
        "    # каждый фрагмент будем разбивать на чанки с помощью RecursiveCharacterTextSplitter\n",
        "    # допишем иерархию заголовков в конец чанка\n",
        "    # унаследуем метаданные от первого сплиттера\n",
        "    # добавим в метаданные размер чанка в токенах\n",
        "      for i,chunk in enumerate(splitter.split_text(fragment.page_content)):\n",
        "        mdata = fragment.metadata.copy()\n",
        "        add_hierarchy = f'{header_string}: уровень {level} пункт {i+1}'\n",
        "        new_chunk = ' '.join([chunk, f'\\nРаздел: {add_hierarchy}'])\n",
        "        mdata[\"len\"] = num_tokens(new_chunk)\n",
        "        doc = Document(page_content=new_chunk, metadata=mdata)\n",
        "        source_chunks.append(doc)\n",
        "\n",
        "    return source_chunks\n",
        "\n",
        "# функция для очистки списка строк от повторений (для формирования более корректного точного саммари)\n",
        "def list_cleaner(list_to_clean):\n",
        "  filtered_list = [value.replace('\"', '').strip() for value in list_to_clean if value.replace('\"', '').strip() != '']\n",
        "  text = ', '.join(filtered_list).replace('\\n', ',').replace('-', ' ')\n",
        "  phrases = text.split(',')\n",
        "  return list(set(map(str.strip, text.split(','))))\n",
        "\n",
        "# Запуск модели  суфлера при первом обращении клиента\n",
        "def sufler(history_user):\n",
        "  hello_completion = get_hello(MODEL,history_user[0],0.4,0)\n",
        "  hello = hello_completion.choices[0].message.content\n",
        "  try:\n",
        "      hello_word = str(hello).split(': ')[1]+ ' '\n",
        "  except:\n",
        "      hello_word = str(hello)\n",
        "\n",
        "  hello_word = hello_word.capitalize().rstrip(string.punctuation) + ', '\n",
        "\n",
        "  if 'None' in hello_word: hello_word='Здравствуйте,'  # если пользователь не поздоровался, то мы поздороваемся нейтрально-формально\n",
        "\n",
        "  return hello_word\n",
        "\n",
        "# Функция удаления перехода на новую строку\n",
        "def remove_newlines(text):\n",
        "    cleaned_string = text.replace('\\n', ' ')\n",
        "    return cleaned_string\n",
        "\n",
        "#фунция добавления переходов на новую строку для удобства чтения\n",
        "# здесь в параметр text подается текст без переносов строки\n",
        "# функция добавит переходы на новую строку при достижении max_len символов\n",
        "def insert_newlines(text: str, max_len: int = 160) -> str:\n",
        "      words = text.split()\n",
        "      lines = []\n",
        "      current_line = \"\"\n",
        "      for word in words:\n",
        "          if len(current_line + \" \" + word) > max_len:\n",
        "              lines.append(current_line)\n",
        "              current_line = \"\"\n",
        "          current_line += f' {word}'\n",
        "      lines.append(current_line)\n",
        "      return \"\\n\".join(lines)\n",
        "\n",
        "#функция добавления переходов на новую строку для удобства чтения\n",
        "# здесь в параметр text подается текст, содержащий переносы строки\n",
        "# функция добавит переходы на новую строку при достижении max_len символов\n",
        "def insert_newlines_n(text: str, max_len: int = 150) -> str:\n",
        "    lines = text.splitlines()\n",
        "    new_lines = []\n",
        "    for line in lines:\n",
        "        words = line.split()\n",
        "        current_line = \"\"\n",
        "        for word in words:\n",
        "            if len(current_line + \" \" + word) > max_len:\n",
        "                new_lines.append(current_line)\n",
        "                current_line = \"\"\n",
        "            current_line += f' {word}'\n",
        "        new_lines.append(current_line)\n",
        "    return \"\\n\".join(new_lines)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eDB42hn484n0"
      },
      "outputs": [],
      "source": [
        "#@title Ансамбль моделей для формирования ответа нейро-продажника\n",
        "\n",
        "def get_seller_answer(history_user, history_manager, history_chat):\n",
        "    output_router_list = []\n",
        "\n",
        "    global needs_extractor\n",
        "    global benefits_extractor\n",
        "    global objection_detector\n",
        "    global resolved_objection_detector\n",
        "    global tariff_detector\n",
        "\n",
        "    global summarized_dialog\n",
        "\n",
        "\n",
        "    # 1. Выделим потребности из последнего сообщения клиента  и добавим в историю потребностей\n",
        "    output_ne = extract_entity_from_statement(\n",
        "                      name=name_needs_extractor,\n",
        "                      system=system_prompt_needs_extractor,\n",
        "                      instructions=instructions_needs_extractor,\n",
        "                      question=history_user[-1],\n",
        "                      history='',\n",
        "                      temp=temperature_needs_extractor,\n",
        "                      verbose=verbose_needs_extractor,\n",
        "                      model=model_needs_extractor).choices[0].message.content\n",
        "    try:\n",
        "      output_needs_extractor = str(output_ne).split(':')[1]+ ''\n",
        "    except:\n",
        "      output_needs_extractor = str(output_ne)\n",
        "    needs_extractor.append(output_needs_extractor)\n",
        "    needs_extractor = list_cleaner(needs_extractor)\n",
        "\n",
        "    # 2. Выделим названные менеджером преимущества, добавим в историю озвученных преимуществ\n",
        "    output_be = extract_entity_from_statement(\n",
        "                      name=name_benefits_extractor,\n",
        "                      system=system_prompt_benefits_extractor,\n",
        "                      instructions=instructions_benefits_extractor,\n",
        "                      question='',\n",
        "                      history=history_manager,\n",
        "                      temp=temperature_benefits_extractor,\n",
        "                      verbose=verbose_benefits_extractor,\n",
        "                      model=model_benefits_extractor).choices[0].message.content\n",
        "    try:\n",
        "      output_benefits_extractor = str(output_be).split(':')[1]+ ''\n",
        "    except:\n",
        "      output_benefits_extractor = str(output_be)\n",
        "    benefits_extractor.append(output_benefits_extractor)\n",
        "    benefits_extractor = list_cleaner(benefits_extractor)\n",
        "\n",
        "    #3. Выделим наличие возражений, добавим их в историю возражений\n",
        "    output_obj = extract_entity_from_statement(\n",
        "                      name=name_objection_detector,\n",
        "                      system=system_prompt_objection_detector,\n",
        "                      instructions=instructions_objection_detector,\n",
        "                      question=history_user[-1],\n",
        "                      history='',\n",
        "                      temp=temperature_objection_detector,\n",
        "                      verbose=verbose_objection_detector,\n",
        "                      model=model_objection_detector).choices[0].message.content\n",
        "    try:\n",
        "        output_objection_detector = str(output_obj).split(':')[1]+ ''\n",
        "    except:\n",
        "        output_objection_detector = str(output_obj)\n",
        "    objection_detector.append(output_objection_detector)\n",
        "    objection_detector = list_cleaner(objection_detector)\n",
        "\n",
        "    #4. Выделим отработанные менеджером возражения клиента, добавим их в историю отработанных возражений\n",
        "    output_res = extract_entity_from_statement(\n",
        "                      name=name_resolved_objection_detector,\n",
        "                      system=system_prompt_resolved_objection_detector,\n",
        "                      instructions=instructions_resolved_objection_detector,\n",
        "                      question='',\n",
        "                      history=history_manager,\n",
        "                      temp=temperature_resolved_objection_detector,\n",
        "                      verbose=verbose_resolved_objection_detector,\n",
        "                      model=model_resolved_objection_detector).choices[0].message.content\n",
        "    try:\n",
        "        output_resolved_objection_detector = str(output_res).split(':')[1]+ ''\n",
        "    except:\n",
        "        output_resolved_objection_detector = str(output_res)\n",
        "    resolved_objection_detector.append(output_resolved_objection_detector)\n",
        "    resolved_objection_detector = list_cleaner(resolved_objection_detector)\n",
        "\n",
        "    #5. Выделим названные менеджером тарифы и цены, добавим их в историю названных тарифов и цен\n",
        "    output_tar = extract_entity_from_statement(\n",
        "                      name=name_tariff_detector,\n",
        "                      system=system_prompt_tariff_detector,\n",
        "                      instructions=instructions_tariff_detector,\n",
        "                      question='',\n",
        "                      history=history_manager,\n",
        "                      temp=temperature_tariff_detector,\n",
        "                      verbose=verbose_tariff_detector,\n",
        "                      model=model_tariff_detector).choices[0].message.content\n",
        "    try:\n",
        "        output_tariff_detector = str(output_tar).split(':')[1]+ ''\n",
        "    except:\n",
        "        output_tariff_detector = str(output_tar)\n",
        "    tariff_detector.append(output_tariff_detector)\n",
        "    tariff_detector = list_cleaner(tariff_detector)\n",
        "\n",
        "    #6. Выделим ключи из последних сообщений клиента и менеджера (предыдущий вопрос+ответ)\n",
        "    k = 2 if len(history_user)>1 else 1\n",
        "    if history_manager and len(history_manager)>0:\n",
        "      manager_list = history_manager[-1:]\n",
        "    else:\n",
        "      manager_list = []\n",
        "\n",
        "    topicphrase_completion = get_topicphrase_questions(name=name_todo_base,\n",
        "                                _user=history_user[-k:],\n",
        "                                _manager = manager_list,\n",
        "                                system=system_topicphrase_extractor,\n",
        "                                instruction=instructions_topicphrase_extractor,\n",
        "                                temp=temperature_todo_base,\n",
        "                                verbose=verbose_base,\n",
        "                                model=model_todo_base)\n",
        "    topicphrase_answ = topicphrase_completion.choices[0].message.content\n",
        "\n",
        "    # именно general_topic_phrase будем подавать в Langchain для similary search, преобразуем в строку-перечисление через запятую + добавляем текущий вопрос клиента\n",
        "    general_topic_phrase = str(history_user[-1]+', ' + topicphrase_answ).replace('[','') .replace(']','').replace(\"'\",'').replace(\"'\",'')\n",
        "\n",
        "    #7. Суммаризируем хронологию предыдущих сообщений диалога\n",
        "    summarized_comp = summarize_dialog(summarized_dialog, history_chat, temp=0.1, verbose=verbose_router, model=MODEL)\n",
        "    summarized_dialog = summarized_comp.choices[0].message.content\n",
        "\n",
        "    #8. Создаем точное саммари с ключевыми моментами диалога\n",
        "    tochnoe_summary = f'''\n",
        "# 1. Выявлены Потребности: {', '.join(needs_extractor) if needs_extractor else 'потребностей не обнаружено'}\n",
        "# 2. Расказанные Преимущества: {', '.join(benefits_extractor) if benefits_extractor else 'преимущества не были рассказаны'}\n",
        "# 3. Возражения клиента: {', '.join(objection_detector) if objection_detector else 'возражений не обнаружено'}\n",
        "# 4. Возражения клиента отработаны: {', '.join(resolved_objection_detector) if resolved_objection_detector else 'отработки не обнаружено'}\n",
        "# 5. Конкретика - оговоренная конкретика - курсы, цены: {', '.join(tariff_detector) if tariff_detector else 'не обнаружено'}\n",
        "'''\n",
        "    #9. Запускаем Диспетчера\n",
        "    output_router = user_question_router(name= name_router,\n",
        "                                        system=system_prompt_router,\n",
        "                                        instructions=instructions_router,\n",
        "                                        question=history_user[-1],\n",
        "                                        summary_history=summarized_dialog,\n",
        "                                        summary_exact=tochnoe_summary,\n",
        "                                        temp=temperature_router,\n",
        "                                        verbose=verbose_router,\n",
        "                                        model=model_router,\n",
        "                                        needs_lst=needs_extractor).choices[0].message.content\n",
        "\n",
        "    #10. По списку спецов из ответа Диспетчера запускаем спецов:\n",
        "    output_spez = []\n",
        "    try:\n",
        "        output_router_fixed = (str(output_router).split(':')[1]+ '').replace(\"‘\", '\"').replace(\"'\", '\"')\n",
        "    except:\n",
        "        output_router_fixed = str(output_router).replace(\"‘\", '\"').replace(\"'\", '\"')\n",
        "\n",
        "    try:\n",
        "      output_router_list = json.loads(output_router_fixed)\n",
        "    except:\n",
        "      output_router_list = ['Zoom_Пуш', 'Спец_по_презентациям']\n",
        "    print(f'{bcolors.RED}{output_router_list}{bcolors.ENDC}')\n",
        "    try:\n",
        "      for key_param in output_router_list:\n",
        "          param = spez_config[key_param] | {'question': history_user[-1],\n",
        "                                      'summary_history': summarized_dialog,\n",
        "                                      'summary_exact': tochnoe_summary,\n",
        "                                      'base_topicphrase': general_topic_phrase,\n",
        "                                      'search_index': vectordb}\n",
        "          spez_answer = spez_user_question(**param).choices[0].message.content\n",
        "          try:\n",
        "            answer = spez_answer.split(': ')[1]+ ' '\n",
        "          except:\n",
        "            answer = spez_answer\n",
        "          answer = answer.lstrip('#3')\n",
        "\n",
        "          output_spez.append(f'{param[\"name\"]}: {answer}')\n",
        "\n",
        "      if verbose: print(f\"\\n{bcolors.BGMAGENTA}Ответы спецов:{bcolors.ENDC}\\n\", '\\n\\n=========\\n'.join(output_spez))\n",
        "    except:\n",
        "      if verbose: print(f'{bcolors.BGYELLOW}Ответ диспетчера либо не вызывает спецов либо имеет неверный формат:{bcolors.ENDC} {output_router}')\n",
        "\n",
        "\n",
        "    #11. На основании предлоажения узких спецов запускаем страшего менеджера для подготовки комплексного ответа:\n",
        "    output_senior = senior_answer(\n",
        "                          name=name_senior,\n",
        "                          system=system_prompt_senior,\n",
        "                          instructions=instructions_senior,\n",
        "                          question=history_user[-1],\n",
        "                          output_spez=output_spez,\n",
        "                          summary_history=summarized_dialog,\n",
        "                          base_topicphrase=general_topic_phrase,\n",
        "                          search_index=vectordb,\n",
        "                          summary_exact=tochnoe_summary,\n",
        "                          temp=temperature_senior,\n",
        "                          verbose=verbose_senior,\n",
        "                          k=num_fragments_base_senior,\n",
        "                          model=model_senior,\n",
        "                          spez_list=output_router_list).choices[0].message.content\n",
        "    if verbose: print(f\"\\n{bcolors.BGMAGENTA}senior: {bcolors.ENDC} {output_senior}\", )\n",
        "    #12. Запускаем Стилиста:\n",
        "    output_stilist = stilizator_answer(\n",
        "                          name=name_stilist,\n",
        "                          system=system_prompt_stilist,\n",
        "                          instructions=instructions_stilist,\n",
        "                          answers_content=output_senior,\n",
        "                          temp=temperature_stilist,\n",
        "                          verbose=verbose_stilist,\n",
        "                          model=model_stilist).choices[0].message.content\n",
        "\n",
        "    #13. контрольный выстрел по приветствиям:\n",
        "    output_stilist_withouthello = del_hello(\n",
        "                          name=name_stilist,\n",
        "                          system=system_prompt_stilist1,\n",
        "                          instructions=instructions_prompt_stilist1,\n",
        "                          answers_content=output_stilist,\n",
        "                          temp=temperature_stilist,\n",
        "                          verbose=verbose_stilist,\n",
        "                          model=model_stilist).choices[0].message.content\n",
        "\n",
        "    return output_stilist_withouthello\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N9xNJUIQEiB"
      },
      "source": [
        "# Подгружаем ключ API, Базу знаний\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RDxCGn8fLado",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "c2880276-cf10-448c-e072-39057202b03c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret Ni4ka does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-11484d54bcb4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# запустите эту ячейку, если используете секретный ключ в колабе\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ni4ka'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret Ni4ka does not exist."
          ]
        }
      ],
      "source": [
        "# запустите эту ячейку, если используете секретный ключ в колабе\n",
        "from google.colab import userdata\n",
        "key = userdata.get('Ni4ka')\n",
        "os.environ[\"OPENAI_API_KEY\"] = key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsfkcywa8yNi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Загружаем Базу Знаний, индексируем, сохраняем индексы\n",
        "knowledge_db_txt = load_googledoc_by_url(knowledge_db_url)\n",
        "# Разбиваем на чанки\n",
        "docs = split_text(knowledge_db_txt, chunk_size, chunk_overlap)\n",
        "vectordb = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
        "vectordb.save_local('UII_database_markdown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7Qu99ht3hGN"
      },
      "outputs": [],
      "source": [
        "# @title Загружаем индексы Базы Знаний\n",
        "vectordb = FAISS.load_local('/content/UII_database_markdown', OpenAIEmbeddings())\n",
        "\n",
        "print('Индексирование Базы Знаний завершено!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJxHiJDvWhUn"
      },
      "source": [
        "# Диалог"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-UsPPZ5Sxry",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Запуск диалога\n",
        "history_chat = []\n",
        "history_user = []\n",
        "history_manager = []\n",
        "\n",
        "needs_extractor = []\n",
        "benefits_extractor = []\n",
        "objection_detector = []\n",
        "resolved_objection_detector = []\n",
        "tariff_detector = []\n",
        "\n",
        "main_answer = ''\n",
        "summarized_dialog = ''\n",
        "\n",
        "while True:\n",
        "    client_question = input(f'{bcolors.BGCYAN}Вопрос клиента:{bcolors.ENDC} ')\n",
        "    history_user.append(client_question)\n",
        "    history_chat.append(f\"Клиент: {client_question}\")\n",
        "    if len(history_user) == 1: hello_word = sufler(history_user)  # запомнили приветствие\n",
        "    if client_question.lower() in ['stop', 'стоп']:\n",
        "        break\n",
        "    without_hello = get_seller_answer(history_user, history_manager, history_chat)\n",
        "    if len(history_chat) == 1 and 'None' not in hello_word:\n",
        "        main_answer = f'{hello_word} меня зовут Василий, я менеджер отдела продаж УИИ. ' + without_hello\n",
        "    else:\n",
        "        main_answer = without_hello\n",
        "\n",
        " #   print(f'{bcolors.BGGREEN}Василий:{bcolors.ENDC}\\n {insert_newlines(remove_newlines(main_answer), 160)}')\n",
        "    print(f'{bcolors.BGGREEN}Василий:{bcolors.ENDC} {remove_newlines(main_answer)}')\n",
        "\n",
        "    history_chat.append(f\"Менеджер: {without_hello}\")\n",
        "    history_manager.append(without_hello) # не будем Василия хранить в истории, чтобы не путать gpt лишними именами\n",
        "\n",
        "# Запуск сохранения\n",
        "from datetime import datetime\n",
        "text_file = f'dialog_{datetime.now().strftime(\"%d.%m.%Y_%H.%M.%S\")}.txt'\n",
        "with open(text_file, \"w\") as f:\n",
        "    f.write(str('\\n\\n'.join(history_chat)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WAxpYmklPhpC",
        "EO2xc8JBAsK-",
        "WLsRxipoEL4c",
        "e-pEOGjVFC1U",
        "BtoExk0PGXe7",
        "fyVzAGhEGwqU",
        "L2kh_CODJ8vJ",
        "HuM8rU70KS0B",
        "kIa-O9GLMlcG",
        "3-TE4WcvPGhn",
        "CJywUK05TeH7",
        "N9qrgfUAPwoU",
        "3IZ8mY8xSWhg"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}